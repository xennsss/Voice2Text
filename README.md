# üé§ Quick Transcribe: Transcriptor de Audio/Video (Flask + Whisper)

Este proyecto es una API web simple construida con Flask que utiliza el modelo de *Machine Learning* **OpenAI Whisper** para transcribir archivos de audio (`.wav`) y video (`.mp4`) a texto.

La aplicaci√≥n est√° dise√±ada para ser altamente portable, ya que utiliza librer√≠as nativas de Python (`torchaudio`) para el procesamiento de audio, eliminando la necesidad de instalar el ejecutable externo `ffmpeg.exe` en el sistema.

## ‚ú® Caracter√≠sticas Principales

* **Portabilidad:** No requiere la instalaci√≥n manual de FFmpeg en el sistema.

* **Compatibilidad:** Soporta archivos `.mp4` y `.wav`.

* **Tecnolog√≠a:** Utiliza el modelo `base` de Whisper (ideal para la CPU).

* **Idioma:** Transcripci√≥n forzada al espa√±ol (`language="es"`).

## üõ†Ô∏è Requisitos de Instalaci√≥n

Para ejecutar este proyecto, necesitas **Python 3.8+** y las siguientes librer√≠as:

* `Flask` y `Flask-CORS`: Para configurar la API web.

* `openai-whisper`: El n√∫cleo de transcripci√≥n.

* `torch` y `torchaudio`: Para el procesamiento y decodificaci√≥n portable de archivos (`.mp4` y `.wav`).

* `numpy` y `soundfile`: Para la manipulaci√≥n de arrays de audio.

### 1. Clona el repositorio

git clone https://docs.github.com/es/repositories/creating-and-managing-repositories/quickstart-for-repositories cd quick-transcribe

### 2. Instalar dependencias

Es **fundamental** que instales todas las dependencias especificadas en el archivo `requirements.txt`. Algunas de estas librer√≠as, como `torch` y `torchaudio`, son grandes.

pip install -r requirements.txt

> **Nota sobre PyTorch:** Si tienes una GPU NVIDIA, considera instalar la versi√≥n de PyTorch con soporte CUDA (consulta el sitio oficial de PyTorch).

## üöÄ Uso de la Aplicaci√≥n (Centrado en la Interfaz)

El proceso de uso se realiza en dos sencillos pasos. El Backend se ejecuta como un servicio y todas las operaciones se realizan desde el Frontend (la interfaz web).

### 1. Iniciar el Servicio de Backend (API)

Primero, inicia el servidor Flask para que la API est√© disponible.

Desde la carpeta ra√≠z del proyecto (`quick-transcribe`), ejecuta:

python app.py


El servicio de la API se iniciar√° en `http://127.0.0.1:5000/`. **Deja esta terminal abierta** mientras usas el Frontend.

### 2. Usar la Interfaz de Usuario (Frontend)

Una vez que el Backend est√© corriendo, puedes interactuar con la aplicaci√≥n.

1. **Aseg√∫rate de que la API de Flask est√© corriendo** (Paso 1).

2. **Inicia el Frontend:** Dependiendo de c√≥mo est√© construido tu Frontend (React, HTML est√°tico, etc.), √°brelo en tu navegador.

3. **Interacci√≥n:** Sube el archivo (`.mp4` o `.wav`) a trav√©s de la interfaz web. El Frontend manejar√° internamente la subida y la llamada al endpoint `/transcribe` de la API para obtener el texto.

## ‚öôÔ∏è Uso Directo de la API (Solo para Desarrolladores)

Si deseas interactuar directamente con la API sin usar la interfaz web:

| **M√©todo** | **Endpoint** | **Descripci√≥n** |
| `POST` | `/transcribe` | Sube un archivo (`.mp4` o `.wav`) usando un formulario `multipart/form-data` con el campo `file`. |

#### Ejemplo de uso con cURL:

curl -X POST http://127.0.0.1:5000/transcribe

-H "Content-Type: multipart/form-data"

-F "file=@/ruta/a/tu/archivo.mp4"


## üí° C√≥mo funciona la portabilidad (Importante)

El archivo `app.py` utiliza `whisper.load_audio()`. Esta funci√≥n se encarga de:

1. Decodificar el archivo (`.mp4` o `.wav`) utilizando los c√≥decs internos de PyTorch/Torchaudio.

2. Convertir el audio a **mono**.

3. Remuestrear el audio a **16000 Hz** (el requisito exacto de Whisper).

Esto elimina el paso manual de instalar y configurar el ejecutable `ffmpeg.exe` para el usuario final.